<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Tag: linux | Blues 小站]]></title>
  <link href="http://www.shenyanchao.cn/tags/linux/atom.xml" rel="self"/>
  <link href="http://www.shenyanchao.cn/"/>
  <updated>2014-11-14T14:02:34+08:00</updated>
  <id>http://www.shenyanchao.cn/</id>
  <author>
    <name><![CDATA[ShenYanchao]]></name>
    <email><![CDATA[zhiyi.shen@gmail.com]]></email>
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Hadoop1.2.1安装部署]]></title>
    <link href="http://www.shenyanchao.cn/blog/2014/11/13/install-hadoop/"/>
    <updated>2014-11-13T13:24:00+08:00</updated>
    <id>http://www.shenyanchao.cn/blog/2014/11/13/install-hadoop</id>
    <content type="html"><![CDATA[<h3>安装需求</h3>

<ul>
<li>Java 1.6</li>
<li>ssh,sshd正常安装</li>
</ul>


<p>确保可以ssh到localhost，并且不需要密码</p>

<pre><code>ssh localhost
</code></pre>

<p> 如果报错，connect to host localhost port 22:Connection refused。说明ssh-server未安装或者未启动。
 运行：</p>

<pre><code>ps -ef | grep sshd 
</code></pre>

<p>查看sshd进程是否存在，如果不存在，说明没有安装。那么进行安装。</p>

<pre><code>sudo apt-get install openssh-server
</code></pre>

<p>然后再执行<code>ssh localhost</code>,如果不能无密码登陆，需要做一下操作：</p>

<pre><code>    ssh-keygen -t dsa -P '' -f ~/.ssh/id_dsa 
    cat ~/.ssh/id_dsa.pub &gt;&gt; ~/.ssh/authorized_keys
</code></pre>

<!--more-->


<h3>相关软件</h3>

<p>Ubuntu Linux为例：</p>

<pre><code> sudo apt-get install ssh 
 sudo apt-get install rsync
</code></pre>

<h3>Hadoop下载</h3>

<p>从<a href="http://hadoop.apache.org/releases.html">Hadoop官网</a>下载一个稳定版，这里就是1.2.1版本啦。</p>

<pre><code>wget http://mirror.bit.edu.cn/apache/hadoop/common/hadoop-1.2.1/hadoop-1.2.1.tar.gz
</code></pre>

<p> ###启动Hadoop</p>

<p> 1.解压<code>tar -xzvf hadoop-1.2.1.tar.gz</code>，进入conf/hadoop-env.sh，设置JAVA_HOME为你的JDK目录。</p>

<pre><code>export JAVA_HOME=/path/to/java/home
</code></pre>

<p> 2.进入/hadoop-1.2.1目录，运行<code>bin\hadoop</code>,会显示hadoop的使用说明信息。</p>

<pre><code>  Usage: hadoop [--config confdir] COMMAND
  where COMMAND is one of:
  namenode -format     format the DFS filesystem
  secondarynamenode    run the DFS secondary namenode
  namenode             run the DFS namenode
  datanode             run a DFS datanode
  dfsadmin             run a DFS admin client
  mradmin              run a Map-Reduce admin client
  fsck                 run a DFS filesystem checking utility
  fs                   run a generic filesystem user client
  balancer             run a cluster balancing utility
  oiv                  apply the offline fsimage viewer to an fsimage
  fetchdt              fetch a delegation token from the NameNode
  jobtracker           run the MapReduce job Tracker node
  pipes                run a Pipes job
  tasktracker          run a MapReduce task Tracker node
  historyserver        run job history servers as a standalone daemon
  job                  manipulate MapReduce jobs
  queue                get information regarding JobQueues
  version              print the version
  jar &lt;jar&gt;            run a jar file
  distcp &lt;srcurl&gt; &lt;desturl&gt; copy file or directories recursively
  distcp2 &lt;srcurl&gt; &lt;desturl&gt; DistCp version 2
  archive -archiveName NAME -p &lt;parent path&gt; &lt;src&gt;* &lt;dest&gt; create a hadoop archive
  classpath            prints the class path needed to get the
                       Hadoop jar and the required libraries
  daemonlog            get/set the log level for each daemon
 or
  CLASSNAME            run the class named CLASSNAME
Most commands print help when invoked w/o parameters.
</code></pre>

<p>  你可以下3中模式来启动hadoop：</p>

<ul>
<li>本地(standalone)模式</li>
<li>伪分布(Pseudo-Distributed)式</li>
<li>全分布(Full-Distributed)式</li>
</ul>


<h4>本地(Standalone)模式安装</h4>

<p>  默认情况下，Hadoop就是单机本地模式。方便调试。 <br/>
  下面是一个样例，复制conf目录到input作为输入，找出符合正则的文件，输出到output目录</p>

<pre><code>    $ mkdir input 
    $ cp conf/*.xml input 
    $ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+' 
    $ cat output/*
</code></pre>

<h4>伪分布(Pseudo-Distributed)式</h4>

<p>配置conf/core-site.xml</p>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;fs.default.name&lt;/name&gt;
         &lt;value&gt;hdfs://localhost:9000&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>配置conf/hdfs-site.xml</p>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;dfs.replication&lt;/name&gt;
         &lt;value&gt;1&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>配置conf/mapred-site.xml:</p>

<pre><code>&lt;configuration&gt;
     &lt;property&gt;
         &lt;name&gt;mapred.job.tracker&lt;/name&gt;
         &lt;value&gt;localhost:9001&lt;/value&gt;
     &lt;/property&gt;
&lt;/configuration&gt;
</code></pre>

<p>  格式化一个新的distributed-filesystem</p>

<pre><code> bin/hadoop namenode -format
</code></pre>

<p> 启动hadoop：</p>

<pre><code>bin/start-all.sh
</code></pre>

<p>  此时可以通过WEB UI控制台来监控NameNode，JobTracker，TaskTracker</p>

<ul>
<li>NameNode - <a href="http://localhost:50070/dfshealth.jsp/">http://localhost:50070/dfshealth.jsp/</a></li>
<li>JobTracker - <a href="http://localhost:50030/jobtracker.jsp/">http://localhost:50030/jobtracker.jsp/</a>
-TaskTracker - <a href="http://localhost:50060/tasktracker.jsp">http://localhost:50060/tasktracker.jsp</a></li>
</ul>


<p> 下面使用distributed filesystem来跑样例:
 拷贝conf目录到hadoop的input目录，此时可以在控制台看到创建了目录。</p>

<pre><code>$ bin/hadoop fs -put conf input
</code></pre>

<p>运行:</p>

<pre><code>$ bin/hadoop jar hadoop-examples-*.jar grep input output 'dfs[a-z.]+'
</code></pre>

<p>检查结果：</p>

<p>拷贝output目录到本地并检查:</p>

<pre><code>$ bin/hadoop fs -get output output 
$ cat output/*
</code></pre>

<p>或者直接在distributed filesystem查看:</p>

<pre><code>$ bin/hadoop fs -cat output/*
</code></pre>

<p>使用完，可以这样来关闭：</p>

<pre><code>$ bin/stop-all.sh
</code></pre>

<p> ###Hadoop分布式部署</p>

<h2> 详见<a href="http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html">http://hadoop.apache.org/docs/r1.2.1/cluster_setup.html</a></h2>

<p>参考文档：<a href="http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html">http://hadoop.apache.org/docs/r1.2.1/single_node_setup.html</a></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[SSH原理]]></title>
    <link href="http://www.shenyanchao.cn/blog/2013/11/26/the-principle-of-ssh/"/>
    <updated>2013-11-26T16:04:00+08:00</updated>
    <id>http://www.shenyanchao.cn/blog/2013/11/26/the-principle-of-ssh</id>
    <content type="html"><![CDATA[<h3>一、什么是SSH？</h3>

<p>简单说，SSH是一种网络协议，用于计算机之间的加密登录。</p>

<p>如果一个用户从本地计算机，使用SSH协议登录另一台远程计算机，我们就可以认为，这种登录是安全的，即使被中途截获，密码也不会泄露。</p>

<p>最早的时候，互联网通信都是明文通信，一旦被截获，内容就暴露无疑。1995年，芬兰学者Tatu Ylonen设计了SSH协议，将登录信息全部加密，成为互联网安全的一个基本解决方案，迅速在全世界获得推广，目前已经成为Linux系统的标准配置。</p>

<p>需要指出的是，SSH只是一种协议，存在多种实现，既有商业实现，也有开源实现。本文针对的实现是OpenSSH，它是自由软件，应用非常广泛。</p>

<!--more-->


<h3>二、最基本的用法</h3>

<p>SSH主要用于远程登录。假定你要以用户名user，登录远程主机host，只要一条简单命令就可以了。</p>

<pre><code>$ ssh user@host
</code></pre>

<p>如果本地用户名与远程用户名一致，登录时可以省略用户名。</p>

<pre><code>$ ssh host
</code></pre>

<p>SSH的默认端口是22，也就是说，你的登录请求会送进远程主机的22端口。使用p参数，可以修改这个端口。</p>

<p>　　$ ssh -p 2222 user@host</p>

<p>上面这条命令表示，ssh直接连接远程主机的2222端口。</p>

<h3>三、中间人攻击</h3>

<p>SSH之所以能够保证安全，原因在于它采用了公钥加密。</p>

<p>整个过程是这样的：（1）远程主机收到用户的登录请求，把自己的公钥发给用户。（2）用户使用这个公钥，将登录密码加密后，发送回来。（3）远程主机用自己的私钥，解密登录密码，如果密码正确，就同意用户登录。  <br/>
这个过程本身是安全的，但是实施的时候存在一个风险：如果有人截获了登录请求，然后冒充远程主机，将伪造的公钥发给用户，那么用户很难辨别真伪。因为不像https协议，SSH协议的公钥是没有证书中心（CA）公证的，也就是说，都是自己签发的。</p>

<p>可以设想，如果攻击者插在用户与远程主机之间（比如在公共的wifi区域），用伪造的公钥，获取用户的登录密码。再用这个密码登录远程主机，那么SSH的安全机制就荡然无存了。这种风险就是著名的"中间人攻击"（Man-in-the-middle attack）。 <br/>
SSH协议是如何应对的呢？</p>

<h3>四、口令登录</h3>

<p>如果你是第一次登录对方主机，系统会出现下面的提示：</p>

<pre><code>$ ssh user@host
The authenticity of host 'host (12.18.429.21)' can't be established.
RSA key fingerprint is 98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d.
Are you sure you want to continue connecting (yes/no)?
</code></pre>

<p>这段话的意思是，无法确认host主机的真实性，只知道它的公钥指纹，问你还想继续连接吗？  <br/>
所谓"公钥指纹"，是指公钥长度较长（这里采用RSA算法，长达1024位），很难比对，所以对其进行MD5计算，将它变成一个128位的指纹。上例中是98:2e:d7:e0:de:9f:ac:67:28:c2:42:2d:37:16:58:4d，再进行比较，就容易多了。   <br/>
很自然的一个问题就是，用户怎么知道远程主机的公钥指纹应该是多少？回答是没有好办法，远程主机必须在自己的网站上贴出公钥指纹，以便用户自行核对。   <br/>
假定经过风险衡量以后，用户决定接受这个远程主机的公钥。</p>

<pre><code>Are you sure you want to continue connecting (yes/no)? yes
</code></pre>

<p>系统会出现一句提示，表示host主机已经得到认可。</p>

<pre><code>Warning: Permanently added 'host,12.18.429.21' (RSA) to the list of known hosts.
</code></pre>

<p>然后，会要求输入密码。</p>

<pre><code>Password: (enter password)
</code></pre>

<p>如果密码正确，就可以登录了。   <br/>
当远程主机的公钥被接受以后，它就会被保存在文件$HOME/.ssh/known_hosts之中。下次再连接这台主机，系统就会认出它的公钥已经保存在本地了，从而跳过警告部分，直接提示输入密码。   <br/>
每个SSH用户都有自己的known_hosts文件，此外系统也有一个这样的文件，通常是/etc/ssh/ssh_known_hosts，保存一些对所有用户都可信赖的远程主机的公钥。</p>

<h3>五、公钥登录</h3>

<p>使用密码登录，每次都必须输入密码，非常麻烦。好在SSH还提供了公钥登录，可以省去输入密码的步骤。   <br/>
所谓"公钥登录"，原理很简单，就是用户将自己的公钥储存在远程主机上。登录的时候，远程主机会向用户发送一段随机字符串，用户用自己的私钥加密后，再发回来。远程主机用事先储存的公钥进行解密，如果成功，就证明用户是可信的，直接允许登录shell，不再要求密码。   <br/>
这种方法要求用户必须提供自己的公钥。如果没有现成的，可以直接用ssh-keygen生成一个：</p>

<pre><code>$ ssh-keygen
</code></pre>

<p>运行上面的命令以后，系统会出现一系列提示，可以一路回车。其中有一个问题是，要不要对私钥设置口令（passphrase），如果担心私钥的安全，这里可以设置一个。</p>

<p>运行结束以后，在$HOME/.ssh/目录下，会新生成两个文件：id_rsa.pub和id_rsa。前者是你的公钥，后者是你的私钥。   <br/>
这时再输入下面的命令，将公钥传送到远程主机host上面：</p>

<pre><code>$ ssh-copy-id user@host
</code></pre>

<p>好了，从此你再登录，就不需要输入密码了。    <br/>
如果还是不行，就打开远程主机的/etc/ssh/sshd_config这个文件，检查下面几行前面"#"注释是否取掉。</p>

<pre><code>RSAAuthentication yes
PubkeyAuthentication yes
AuthorizedKeysFile .ssh/authorized_keys
</code></pre>

<p>然后，重启远程主机的ssh服务。</p>

<pre><code>// ubuntu系统
service ssh restart
// debian系统
/etc/init.d/ssh restart
</code></pre>

<h3>六、authorized_keys文件</h3>

<p>远程主机将用户的公钥，保存在登录后的用户主目录的$HOME/.ssh/authorized_keys文件中。公钥就是一段字符串，只要把它追加在authorized_keys文件的末尾就行了。</p>

<p>这里不使用上面的ssh-copy-id命令，改用下面的命令，解释公钥的保存过程：</p>

<pre><code>$ ssh user@host 'mkdir -p .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys' &lt; ~/.ssh/id_rsa.pub     
</code></pre>

<p>这条命令由多个语句组成，依次分解开来看： <br/>
（1）<code>$ ssh user@host</code>，表示登录远程主机； <br/>
（2）单引号中的<code>mkdir .ssh &amp;&amp; cat &gt;&gt; .ssh/authorized_keys</code>，表示登录后在远程shell上执行的命令： <br/>
（3）<code>$ mkdir -p .ssh</code>的作用是，如果用户主目录中的.ssh目录不存在，就创建一个;   <br/>
（4）<code>cat &gt;&gt; .ssh/authorized_keys' &lt; ~/.ssh/id_rsa.pub</code>的作用是，将本地的公钥文件<code>~/.ssh/id_rsa.pub</code>，重定向追加到远程文件authorized_keys的末尾。    <br/>
写入authorized_keys文件后，公钥登录的设置就完成了。</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Web系统性能调优常用技巧]]></title>
    <link href="http://www.shenyanchao.cn/blog/2013/09/24/performance-tuning-in-web-test/"/>
    <updated>2013-09-24T18:02:00+08:00</updated>
    <id>http://www.shenyanchao.cn/blog/2013/09/24/performance-tuning-in-web-test</id>
    <content type="html"><![CDATA[<h4>目标Web系统</h4>

<p>apache + tomcat + mysql + linux, 介绍如何定位瓶颈与调优</p>

<h4>Tomcat</h4>

<p>按照官方默认配置。 <br/>
并发150正常;达到210时，报connection refuse</p>

<p>$TOMCAT_HOME/conf/server.xml中</p>

<pre><code>&lt;Connector port="8080" protocol="HTTP/1.1"      connectionTimeout="20000" 
               redirectPort="8443" URIEncoding="UTF-8"/&gt;
</code></pre>

<p>maxThreads 默认值是200
acceptCount 默认值是100</p>

<p>解决方法：显式指明以上2项，并提高数值。并可配合min/maxSpareThreads</p>

<p>参数文档： <a href="http://tomcat.apache.org/tomcat-6.0-doc/config/http.html">http://tomcat.apache.org/tomcat-6.0-doc/config/http.html</a></p>

<!--more-->


<p>继续增加并发数，出现以下现象：</p>

<ul>
<li>420并发，观察到Jmeter的聚合报告有明显卡顿现象。</li>
<li><p>Noah监控，显示CPU使用率下降。大锯齿出现。</p>

<p>问题分析：</p>

<pre><code>  在加压过程中，对tomcat的JVM情况进行监控。出现FullGC,每次大概4s .
</code></pre></li>
</ul>


<p>如何监控GC吗？</p>

<pre><code>jstat -gcutil 3950 3000 5

  S0     S1         E          O      P       YGC     YGCT    FGC       FGCT     GCT   
  0.00  47.86  66.10   6.55  99.92      7       0.087     0         0.000    0.087
  0.00  47.86  66.90   6.55  99.94      7       0.087     0         0.000    0.087
  0.00  47.86  67.30   6.55  99.94      7       0.087     0         0.000    0.087
  0.00  47.86  67.30   6.55  99.94      7       0.087     0         0.000    0.087
  0.00  47.86  67.30   6.55  99.94      7       0.087     0         0.000    0.087
</code></pre>

<p>解决方法：</p>

<pre><code>     $TOMCAT_HOME/bin/catalina.sh   第一行添加
    export CATALINA_OPTS="-Xmx3500m -Xms2048m -XX:PermSize=256m XX:MaxPermSize=512m -Xss128k"
</code></pre>

<p>JAVA_OPTS   VS   CATALINA_OPTS（推荐使用）   <br/>
<strong>差别</strong>：JAVA_OPTS start run stop   适用所有JVM</p>

<pre><code>           CATALINA_OPTS   start run    专门配置tomcat    
</code></pre>

<p>tomcat默认-client ，production环境加-server</p>

<p>JVM参数文档：<a href="http://kenwublog.com/docs/java6-jvm-options-chinese-edition.htm">http://kenwublog.com/docs/java6-jvm-options-chinese-edition.htm</a></p>

<h5>Tomcat executor</h5>

<p>据信使用executor后，能在实际中有更好的性能以及稳定性！更为重要的是能在多个connector之间共用。</p>

<pre><code>&lt;Executor name="tomcatThreadPool" namePrefix="catalina-exec-" maxThreads="1000" minSpareThreads="25"/&gt;

&lt;Connector executor="tomcatThreadPool"  port="8080" protocol="HTTP/1.1"   connectionTimeout="20000"  redirectPort="8443" /&gt;  
</code></pre>

<p>此时，connector再使用maxThreads等属性将被忽略。</p>

<h5>Tomcat Connector protocol</h5>

<ul>
<li><p>bio   默认模式，性能低下，无任何优化，阻塞IO模式</p>

<p>  protocol = "org.apache.coyote.http11.Http11Protocol" or HTTP/1.1(for http connector)
  protocol = "org.apache.jk.server.JkCoyoteHandler" or AJP/1.3(for ajp connector)</p></li>
<li><p>nio   Java的异步io技术，非阻塞 IO</p>

<p>  protocol = "org.apache.coyote.http11.Http11NioProtocol"(for http connector)
  protocol = "org.apache.coyote.ajp.AjpProtocol"(for ajp connector)</p></li>
<li><p>apr  需要安装apr(Apache Portable Runtime)和Native。</p>

<p>  protocol = "org.apache.coyote.http11.Http11AprProtocol"(for http connector)
  protocol = "org.apache.coyote.ajp.AjpAprProtocol"  (for ajp connector)</p></li>
</ul>


<p>参考文档：  <br/>
&lt;http://tomcat.apache.org/tomcat-6.0-doc/config/http.html#Connector Comparison></p>

<p><a href="http://tomcat.apache.org/tomcat-6.0-doc/config/ajp.html">http://tomcat.apache.org/tomcat-6.0-doc/config/ajp.html</a></p>

<h5>MySQL</h5>

<p>大并发下，响应时间如何提高，绝大部分瓶颈都处于数据库端。</p>

<p>与数据库的连接，使用JDBC连接池</p>

<p>slow query监控：   <br/>
1. 开启慢查询 my.cnf</p>

<pre><code>long_query_time = 2
log-slow-queries =  slow.log
</code></pre>

<p>2.使用mysqldumpslow分析log</p>

<pre><code>mysqldumpslow -t 10 -s t  slow.log
</code></pre>

<p>解决：</p>

<ul>
<li>1.SQL调优   （http://coolshell.cn/articles/1846.html）</li>
<li>2.走类似lucene索引，空间换时间（idea实际测试中，吞吐提升7倍）</li>
<li>3.使用NoSQL?</li>
</ul>


<p>$MYSQL_HOME/etc/my.cnf  或者 my.ini（windows）</p>

<p>主要影响性能参数：</p>

<pre><code>max-connections = 3000     会话数上限
max_connect_errors = 10000    允许的最大连接错误量
query_cache_size =128M    查询缓存
query_cache_limit = 2M   小于这么大的才缓存，保护查询缓存
sort_buffer_size =256M    排序order by 或 group by 使用
</code></pre>

<p>参考：<a href="http://www.ha97.com/4110.html">http://www.ha97.com/4110.html</a></p>

<h4>Apache</h4>

<p>处理静态资源，无法处理动态（需要应用服务器支持）</p>

<p>静态资源直接交给apache处理</p>

<p>ab 命令进行测试，达到1000并发很easy</p>

<pre><code>ab -k -c 1000  -n 1000000  http://hostname:port/path
</code></pre>

<p>参考：<a href="http://httpd.apache.org/docs/2.2/programs/ab.html">http://httpd.apache.org/docs/2.2/programs/ab.html</a></p>

<h5>开启MPM支持大并发</h5>

<table border="1px">
<thead>
<th>Mpm模式</th><th>并发方式</th><th>内存占用</th><th>并发性能</th>
</thead>
<tbody>
<tr>
<td>prefork</td><td>进程</td><td>高</td><td>低并发下，吞吐率高</td>
</tr>
<tr>
<td>worker</td><td>进程+线程</td><td>低</td><td>支持海量并发</td>
</tr>
</tbody>
</table>


<p>确定apache模式命令：</p>

<pre><code>./httpd –l
</code></pre>

<p>输出：</p>

<pre><code>Compiled in modules:
core.c
worker.c
http_core.c
mod_so.c
</code></pre>

<p>修改httpd-mpm.conf</p>

<pre><code>&lt;IfModule mpm_worker_module&gt;
    StartServers          2
    MaxClients          150
    MinSpareThreads      25
    MaxSpareThreads      75
    ThreadsPerChild      25
    MaxRequestsPerChild   0
&lt;/IfModule&gt;
</code></pre>

<p>上面的配置需要满足以下公式：</p>

<pre><code>     ThreadLimit &gt;= ThreadsPerChild    
     MaxClients &lt;= ServerLimit * ThreadsPerChild 必须是ThreadsPerChild的倍数     
     MaxSpareThreads &gt;= MinSpareThreads+ThreadsPerChild    
</code></pre>

<h4>Linux</h4>

<h5>too many open files error</h5>

<p><code>ulimit -a</code>进行查看
修改<code>vi /etc/security/limits.conf</code></p>

<p>添加：</p>

<pre><code>*    -     nofile    65535
</code></pre>

<p>参考文档： <br/>
 <a href="http://blog.csdn.net/lifeibo/article/details/5972356">http://blog.csdn.net/lifeibo/article/details/5972356</a></p>

<p>Http连接是基于TCP的，这个时候需要对linux服务器进行优化。 <br/>
<strong>三次握手</strong></p>

<p><img src="/images/blog/2013/three-times-handshake.png" alt="三次握手" /></p>

<p><strong>四次挥手</strong></p>

<p><img src="/images/blog/2013/four-wave.png" alt="四次挥手" /></p>

<p>如何查看服务器TCP状态？  <br/>
命令：</p>

<pre><code>netstat -n | awk '/^tcp/ {++S[$NF]} END {for(a in S) print a, S[a]}'
</code></pre>

<p>输出：</p>

<pre><code>ESTABLISHED 1423
FIN_WAIT1 1
FIN_WAIT2 262
SYN_SENT 1
TIME_WAIT 962
</code></pre>

<p>优化TCP连接相关参数：</p>

<p><code>vi /etc/sysctl.conf</code></p>

<pre><code>net.ipv4.tcp_fin_timeout = 30  保持在FIN-WAIT-2的时间。默认60秒。2.2内核是180秒
net.ipv4.tcp_keepalive_time = 1200     长连接keepalive打开，发送的频率。默认7200（2H）
net.ipv4.tcp_tw_reuse = 1     默认0，处于TIME-WAIT状态的socket可以用于新的TCP连接
net.ipv4.tcp_tw_recycle = 1   默认0，TIME-WAIT状态的sockets快速回收
net.ipv4.ip_local_port_range = 1024    65000 向外连接的端口范围，默认32768~61000
net.ipv4.tcp_max_syn_backlog = 8192  默认1024/128,未获得客户端连接请求并保存在队列中的最大数目。
net.ipv4.tcp_max_tw_buckets = 5000   默认180000，系统处理的最大TIME_WAIT数目。
net.ipv4.route.gc_timeout = 100  路由缓存刷新频率，失败多长时间跳到另一个。默认300.
net.ipv4.tcp_syncookies = 1 默认0，SYN队列溢出，启用cookies处理。
net.ipv4.tcp_syn_retries = 1       新建连接发送SYN次数，默认5，180秒
net.ipv4.tcp_synack_retries = 1    3次握手的第二步，重试几次。默认5.
</code></pre>

<p><code>/sbin/sysctl -p</code>   生效</p>

<p>参考文档：<a href="http://www.itlearner.com/article/4792">http://www.itlearner.com/article/4792</a></p>

<p>备注：此文由本人在公司内做的PPT分享制作而成，内容有些省略以及跳跃。欢迎留言。</p>
]]></content>
  </entry>
  
</feed>